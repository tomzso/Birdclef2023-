{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-09T23:21:24.514488Z",
     "start_time": "2023-12-09T23:21:12.467489400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import random\n",
    "import colorednoise as cn\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803ce1c90653ec32",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:09:48.637921Z",
     "start_time": "2023-12-09T17:09:48.633245200Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# All the background audio can be dowloaded from the following links\n",
    "backgrounds = [\n",
    "    '1PYHJtcFm5-gYglJE29-VQE6Rq08pFfUv', # https://drive.google.com/file/d/1PYHJtcFm5-gYglJE29-VQE6Rq08pFfUv/view?usp=drive_link\n",
    "    '1Nx-7p2XLqZqXIku8ptDbRK-_PLfy3e8Q', # https://drive.google.com/file/d/1Nx-7p2XLqZqXIku8ptDbRK-_PLfy3e8Q/view?usp=drive_link\n",
    "    '1mnyNDc4lLfLoCGa1nZt302f6Zj45nB5x', # https://drive.google.com/file/d/1mnyNDc4lLfLoCGa1nZt302f6Zj45nB5x/view?usp=drive_link\n",
    "    '1-aCUcCLFwYQGKUlrDppKudRJHXe_5Cv2', # https://drive.google.com/file/d/1-aCUcCLFwYQGKUlrDppKudRJHXe_5Cv2/view?usp=drive_link\n",
    "    '17gBdhd_l--MbSf6wN1y6F7n_ah6lCTFa', # https://drive.google.com/file/d/17gBdhd_l--MbSf6wN1y6F7n_ah6lCTFa/view?usp=drive_link\n",
    "    '177_yA8z6AxUSFkFif8fF5aieDSZn-73I', # https://drive.google.com/file/d/177_yA8z6AxUSFkFif8fF5aieDSZn-73I/view?usp=drive_link\n",
    "    '1uZRqfKNS2s-_Mi8Q9CndTOuj5-qDzjfQ', # https://drive.google.com/file/d/1uZRqfKNS2s-_Mi8Q9CndTOuj5-qDzjfQ/view?usp=drive_link\n",
    "    '1hYLKFUfYSeNWgYAYbA5OXkNYHtHKChZd', # https://drive.google.com/file/d/1hYLKFUfYSeNWgYAYbA5OXkNYHtHKChZd/view?usp=drive_link\n",
    "    '1GIFshzDrOdahK9IiTt64yQlj6isdmVIa', # https://drive.google.com/file/d/1GIFshzDrOdahK9IiTt64yQlj6isdmVIa/view?usp=drive_link\n",
    "    '1C-bz2GL5_IxOPDKvwk1PQO64st_9vW6Y', # https://drive.google.com/file/d/1C-bz2GL5_IxOPDKvwk1PQO64st_9vW6Y/view?usp=drive_link\n",
    "    '1_OF8Fn6kd2Ibk1_f9TzzYCuFZ6Fe_AFv', # https://drive.google.com/file/d/1_OF8Fn6kd2Ibk1_f9TzzYCuFZ6Fe_AFv/view?usp=drive_link\n",
    "    '1mtQAe0EDPpD98dIJZLqvXMvC-0rIa-s6', #https://drive.google.com/file/d/1mtQAe0EDPpD98dIJZLqvXMvC-0rIa-s6/view?usp=drive_link\n",
    "    '1sM4hQmMWPTE5ruA_adD_xORBi2sLR56P', #https://drive.google.com/file/d/1sM4hQmMWPTE5ruA_adD_xORBi2sLR56P/view?usp=drive_link\n",
    "    '1xLfDhDBthog3OUl67E_Vz-aqbLl5lZ9t', #https://drive.google.com/file/d/1xLfDhDBthog3OUl67E_Vz-aqbLl5lZ9t/view?usp=drive_link\n",
    "    '183gBu0rqiP2j0Sv6RrjH8Ror75KeQtux', #https://drive.google.com/file/d/183gBu0rqiP2j0Sv6RrjH8Ror75KeQtux/view?usp=drive_link\n",
    "    '1E59IPpd4RzfCWINetXjcfQ3D0QZSdZu6', #https://drive.google.com/file/d/1E59IPpd4RzfCWINetXjcfQ3D0QZSdZu6/view?usp=drive_link\n",
    "    '1f5fu38ZzmZ_NUZVePlp1e18DBUMfXPJr', #https://drive.google.com/file/d/1f5fu38ZzmZ_NUZVePlp1e18DBUMfXPJr/view?usp=drive_link\n",
    "    '1axCNi6EclZtvBEmRXXkpxEh3qQh6NyPI', #https://drive.google.com/file/d/1axCNi6EclZtvBEmRXXkpxEh3qQh6NyPI/view?usp=drive_link\n",
    "    '1kmjwuq2LluBwxkKqtK12tnRhPk-B38fc', #https://drive.google.com/file/d/1kmjwuq2LluBwxkKqtK12tnRhPk-B38fc/view?usp=drive_link\n",
    "    '1kswtFDcvMaFRCMdTV-I4Kcy5XwCAEsKd', #https://drive.google.com/file/d/1kswtFDcvMaFRCMdTV-I4Kcy5XwCAEsKd/view?usp=drive_link\n",
    "    '1kb0BB3uqD0mzpACV4XLpIBBOHvuO6z3H', #https://drive.google.com/file/d/1kb0BB3uqD0mzpACV4XLpIBBOHvuO6z3H/view?usp=drive_link\n",
    "\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download the background audio files\n",
    "for i, id in enumerate(backgrounds):\n",
    "  destination = f'{i}.wav'\n",
    "\n",
    "  # Check if the file already exists\n",
    "  if not os.path.exists(destination):\n",
    " \n",
    "    !wget --content-disposition 'https://drive.google.com/uc?export=download&id={id}&confirm=t'\n",
    "\n",
    "\n",
    "# Download the bird audio files (birdclef-2023.zip)\n",
    "\n",
    "!wget --content-disposition 'https://drive.google.com/uc?export=download&id=1dk0qIGOQiXPKKJzNi-uwjcX0-vQ2PQ7j&confirm=t' #  https://drive.google.com/file/d/1dk0qIGOQiXPKKJzNi-uwjcX0-vQ2PQ7j/view?usp=sharing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96974dc24a6ec93b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Replace 'zip_file_path' with the path of the zip file\n",
    "zip_file_path = 'birdclef-2023.zip'\n",
    "\n",
    "# Replace 'output_directory' with the directory where you want to extract the contents\n",
    "output_directory = '/content'\n",
    "\n",
    "# Open the zip file (uzip the file)\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents into the specified directory\n",
    "    zip_ref.extractall(output_directory)\n",
    "\n",
    "print(f\"Files extracted to '{output_directory}'.\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e6a0f65fbb1638c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908efc2f4b024b6b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:09:48.688750500Z",
     "start_time": "2023-12-09T17:09:48.638918900Z"
    }
   },
   "outputs": [],
   "source": [
    "# The number of background are used           \n",
    "background_number = len(backgrounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ca9b9cea9d5dc5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:09:48.690749900Z",
     "start_time": "2023-12-09T17:09:48.658352Z"
    }
   },
   "outputs": [],
   "source": [
    "# The background audio file list\n",
    "background_signals = []\n",
    "\n",
    "# The sample rate of the audio files\n",
    "SAMPLE_RATE = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4bd11dd9eeeb578",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T17:10:05.013020900Z",
     "start_time": "2023-12-09T17:09:48.674750Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# The background audio files (signals) are loaded into a list\n",
    "for i in range(background_number):\n",
    "  background_signal, background_sample_rate = librosa.load(f'{i}.wav', sr=SAMPLE_RATE)\n",
    "  background_signals.append(background_signal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50285c0bba53b347",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T21:08:47.278217300Z",
     "start_time": "2023-12-09T21:08:46.820257400Z"
    }
   },
   "outputs": [],
   "source": [
    "# The bird audio files (signals) are loaded into a list\n",
    "audio_data_X = []\n",
    "\n",
    "# The bird audio files (labels) are loaded into a list\n",
    "audio_data_Y = []\n",
    "\n",
    "# The augmented bird audio files (signals) are loaded into a list\n",
    "augmented_data_X = []\n",
    "\n",
    "# The augmented bird audio files (labels) are loaded into a list\n",
    "augmented_data_Y = []\n",
    "\n",
    "# The labels of the bird audio files are loaded into a list\n",
    "labels = []\n",
    "\n",
    "# The number of bird audio files in each sub-folder\n",
    "label_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85faa87622a6b794",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T21:08:47.297217700Z",
     "start_time": "2023-12-09T21:08:47.053671200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the parameters for the audio files\n",
    "\n",
    "dataset_path = r\"C:\\Users\\hunto\\projects\\jupyterprojects\\kagglebird\\train_audio\"\n",
    "SAMPLE_RATE = 32000\n",
    "N_MELS = 128\n",
    "HOP_LENGHT = 512\n",
    "bird_data_min = 30\n",
    "duration = 5\n",
    "total_sample = duration * SAMPLE_RATE # 5 sec * 32000 sample rate / second\n",
    "\n",
    "rows_per_file = 750\n",
    "\n",
    "file_index = 0\n",
    "augmented_index = 0\n",
    "pink_noise_amplitude = 0.0005 \n",
    "\n",
    "\n",
    "sample_rate = tf.cast(SAMPLE_RATE, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc7d12d7d65443a2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T21:08:47.334217100Z",
     "start_time": "2023-12-09T21:08:47.237347400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# The audio files are converted to 5 second signals  \n",
    "def signal_to_5_sec_duration(signal):\n",
    "    # if the audio duration is lower than 5 second then it repeats the audio until it reaches 5 second duration\n",
    "    if signal.shape[0] < total_sample:\n",
    "      repeated_signal = np.tile(signal, total_sample // len(signal))\n",
    "      remaining_signal = signal[:total_sample % len(signal)]\n",
    "      resulting_signal = np.concatenate((repeated_signal, remaining_signal))\n",
    "      signal = resulting_signal\n",
    "      \n",
    "    # if the audio duration is higher than 5 second then it chooses the first 5 second of the audio\n",
    "    elif signal.shape[0] > total_sample:\n",
    "        signal = signal[:total_sample]\n",
    "        \n",
    "    return signal\n",
    "\n",
    "\n",
    "# The audio files (signals) are converted to spectrogram, chroma feature and mfcc.\n",
    "# The spectrogram, chroma feature and mfcc are stacked along a new axis, so this will be a 3D array\n",
    "# The shape of the 3D array is (128, 313, 3), where 128 is the number of mel bins, 313 is the number of frames, and 3 is the number of channels\n",
    "def signal_to_spectrogram(signal, sample_rate, n_mels, hop_length):\n",
    "    \n",
    "    # Compute the Mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sample_rate, n_mels=n_mels, hop_length=hop_length)\n",
    "\n",
    "    # Take the logarithm to create the Log-Mel Spectrogram\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "\n",
    "    # Compute Chroma Feature with the same hop_length\n",
    "    chroma = librosa.feature.chroma_stft(y=signal, sr=sample_rate, hop_length=hop_length, n_chroma=n_mels)\n",
    "    \n",
    "    # Compute MFCC with the same hop_length\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=N_MELS, hop_length=hop_length)\n",
    "\n",
    "    # Convert the Log-Mel Spectrogram, Chroma, and MFCC to NumPy arrays\n",
    "    log_mel_spectrogram = log_mel_spectrogram.astype('float32')\n",
    "    chroma = chroma.astype('float32')\n",
    "    mfcc = mfcc.astype('float32')\n",
    "    \n",
    "    # Stack the arrays along a new axis\n",
    "    spectrogram = np.stack([log_mel_spectrogram, chroma, mfcc], axis=-1)\n",
    "    \n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4513ef7e068ef27f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T21:08:47.366218100Z",
     "start_time": "2023-12-09T21:08:47.269731800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the number of audio files for each bird\n",
    "# The number of audio files for each bird is printed\n",
    "# The number of audio files for each bird is saved in a dictionary and in a list\n",
    "def get_the_number_of_audio_for_each_bird():\n",
    "    # loop through all genre sub-folder, count total number of files and extract labels into a list\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "      if dirpath is not dataset_path:\n",
    "          # save genre label (i.e., sub-folder name) in the mapping\n",
    "          semantic_label = dirpath.split(\"\\\\\")[-1]\n",
    "\n",
    "          # process all audio files in genre sub-dir\n",
    "          for filename in filenames:\n",
    "              labels.append(semantic_label)\n",
    "              \n",
    "    # Count occurrences manually\n",
    "    for element in labels:\n",
    "        if element in label_counts:\n",
    "            label_counts[element] += 1\n",
    "        else:\n",
    "            label_counts[element] = 1\n",
    "    \n",
    "    # Print the mapping\n",
    "    for element, count in label_counts.items():\n",
    "        print(f\"Element: {element}, Count: {count}\")\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8331dc86e871cfa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_the_number_of_audio_for_each_bird()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94c78c318d8ce178",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T21:08:47.943464200Z",
     "start_time": "2023-12-09T21:08:47.864339700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f7d7c136c7aea5f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T21:08:48.234397600Z",
     "start_time": "2023-12-09T21:08:48.136864Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce9d204c31abf052",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T21:08:48.803899Z",
     "start_time": "2023-12-09T21:08:48.767291800Z"
    }
   },
   "outputs": [],
   "source": [
    "# add audio (spectrogram) and labels to the audio data lists\n",
    "def add_audio(signal, i):\n",
    "    \n",
    "    # convert the audio file to 5 second duration\n",
    "    signal = signal_to_5_sec_duration(signal)\n",
    "    \n",
    "    # convert the audio file to spectrogram (3D array, with chroma feature and mfcc) \n",
    "    log_mel_spectrogram = signal_to_spectrogram(signal,SAMPLE_RATE,N_MELS,HOP_LENGHT)\n",
    "    \n",
    "    # add the spectrogram and label to the audio data lists\n",
    "    audio_data_Y.append(np.array([i]))\n",
    "    audio_data_X.append(log_mel_spectrogram)\n",
    "    \n",
    "# add augmented audio (spectrogram) and labels to the augmented audio data lists\n",
    "def add_augmented(signal, i):\n",
    "    # convert the audio file to 5 second duration\n",
    "    signal = signal_to_5_sec_duration(signal)\n",
    "    # convert the audio file to spectrogram (3D array, with chroma feature and mfcc)\n",
    "    log_mel_spectrogram = signal_to_spectrogram(signal,SAMPLE_RATE,N_MELS,HOP_LENGHT)\n",
    "    \n",
    "    # add the spectrogram and label to the augmented audio data lists\n",
    "    augmented_data_Y.append(np.array([i]))\n",
    "    augmented_data_X.append(log_mel_spectrogram)\n",
    "\n",
    "# add pink noise to the audio file\n",
    "def signal_pinked(signal):\n",
    "    # Get the maximum amplitude of the original audio file\n",
    "    max_amplitude_original = np.max(np.abs(signal))\n",
    "    # Generate the pink noise\n",
    "    pink_noise = cn.powerlaw_psd_gaussian(1, len(signal))\n",
    "    # Adjust the amplitude of the pink noise to your preference\n",
    "    pink_noise *= (pink_noise_amplitude  * max_amplitude_original) \n",
    "    # Combine the pink noise with the original audio\n",
    "    signal_noised = signal + pink_noise\n",
    "\n",
    "    return signal_noised\n",
    "\n",
    "# add background noise to the audio file\n",
    "def signal_with_background(signal):\n",
    "    # Get the maximum amplitude of the original audio file\n",
    "    max_amplitude_original = np.max(np.abs(signal))\n",
    "    \n",
    "    # Choose a random background signal\n",
    "    random_int = random.randint(0, len(background_signals)-1)\n",
    "    \n",
    "    # Get the random background signal\n",
    "    random_background = background_signals[random_int]\n",
    "    \n",
    "    # Choose a random index from the background signal\n",
    "    random_index = random.randint(0, len(random_background) - total_sample)\n",
    "    \n",
    "    # Get the random background signal (a random part of the background noise) with the same length as the audio file (signal)\n",
    "    random_background = random_background[random_index : (random_index + total_sample)]\n",
    "    \n",
    "    # Adjust the amplitude of the background noise with preference\n",
    "    return signal + (random_background * max_amplitude_original)\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a59a4fcfe8c47",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loop through all genre sub-folder\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "    # Check if the folder is not the main folder\n",
    "    if dirpath is not dataset_path:\n",
    "        \n",
    "      # Save genre label (i.e., sub-folder name) in the mapping\n",
    "      semantic_label = dirpath.split(\"\\\\\")[-1]\n",
    "      print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "    \n",
    "      # Process all audio files in genre sub-dir\n",
    "      for filename in filenames:\n",
    "          \n",
    "        # Load the audio file\n",
    "        file_path = os.path.join(dirpath, filename)\n",
    "        \n",
    "        # Get the signal and sample rate of the audio file\n",
    "        signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        \n",
    "        # Print the filename\n",
    "        print(filename)\n",
    "\n",
    "        # Add the audio file to the audio data lists if the number of audio files for the bird is more than 100\n",
    "        if label_counts.get(semantic_label, 0) > 100:\n",
    "            \n",
    "            # If the audio file is longer than total_sample * 6 second then...\n",
    "            if len(signal) >= total_sample * 6:\n",
    "                # Choose a random part of the audio file and augment it by adding background noise\n",
    "                for e in range(2):\n",
    "                    random_part= random.randint(0, len(signal) - total_sample)\n",
    "                    signal_w_background = signal_with_background(signal[random_part : (random_part + total_sample)])\n",
    "                    add_augmented(signal_w_background,i)\n",
    "            else:\n",
    "                    \n",
    "                add_audio(signal[:total_sample],i)\n",
    "\n",
    "              \n",
    "        # If the number of audio files for the bird is between 40 and 100 then...\n",
    "        elif 100 >= label_counts.get(semantic_label, 0) > 40:\n",
    "\n",
    "            # If the audio file is longer than total_sample * 5 second then...\n",
    "            if len(signal) > total_sample * 5:\n",
    "                # Choose a random part of the audio file and augment it by adding background noise\n",
    "                for e in range(3):\n",
    "                    random_part= random.randint(0, len(signal) - total_sample)\n",
    "                    signal_w_background = signal_with_background(signal[random_part : (random_part + total_sample)])\n",
    "                    add_augmented(signal_w_background,i)\n",
    "            else:\n",
    "                # Add the audio file to the audio data lists\n",
    "                if len(signal) > total_sample:\n",
    "                    add_audio(signal[total_sample:],i)\n",
    "                    \n",
    "                add_audio(signal[:total_sample],i)\n",
    "\n",
    "    \n",
    "        # If the number of audio files for the bird is between 15 and 40 then...\n",
    "        elif 40 >= label_counts.get(semantic_label, 0) > 10:\n",
    "            # If the audio file is longer than total_sample * 5 second then...\n",
    "            if len(signal) >= total_sample * 5:\n",
    "                # Choose a random part of the audio file that is not in the first 5 second and augment it by adding background noise    \n",
    "                random_part= random.randint(0, len(signal) - total_sample)\n",
    "                # Create a pink noise and add it to the audio file\n",
    "                signal_pink= signal_pinked(signal)\n",
    "                add_augmented(signal_pink,i)\n",
    "                # Add the audio file to the augmented audio data lists that not includes the first 5 second\n",
    "                add_augmented(signal[random_part : (random_part + total_sample) ],i)\n",
    "                \n",
    "                # Add the audio file to the audio data lists that includes the first 5 second\n",
    "                add_audio(signal[:total_sample],i)\n",
    "\n",
    "                # For 4 times, choose a random part of the audio file that is not in the first 5 second and augment it by adding background noise\n",
    "                for e in range(4):\n",
    "                    random_part= random.randint(0, len(signal) - total_sample)\n",
    "                    signal_w_background = signal_with_background(signal[random_part : (random_part + total_sample)])\n",
    "                    add_augmented(signal_w_background,i)\n",
    "            \n",
    "           \n",
    "            else:\n",
    "                # Add the audio file to the audio data lists\n",
    "                if len(signal) > total_sample:\n",
    "                    add_audio(signal[total_sample:],i)\n",
    "                    \n",
    "                add_audio(signal[:total_sample],i)\n",
    "\n",
    "        # If the number of audio files for the bird is between 2 and 10 then...\n",
    "        elif 10 >= label_counts.get(semantic_label, 0) > 2:\n",
    "            # Create a sub-signal list that includes the audio file divided into 5 second parts\n",
    "            subsignals = [signal[i:i+total_sample] for i in range(0, len(signal), total_sample)]\n",
    "            \n",
    "            # This 0 or 1 value number decides whether data augmented or not\n",
    "            split_random = random.randint(0, 1)\n",
    "            # Iterate through the sub-signal list\n",
    "            for index, subsignal in enumerate(subsignals):\n",
    "                # If the index is even then...\n",
    "                \n",
    "                if split_random == 0:\n",
    "                    # Create a pink noise and add it to augmented audio data lists\n",
    "                    signal_pink = signal_pinked(subsignal)\n",
    "                    add_augmented(signal_pink,i)\n",
    "                    \n",
    "                    # Add the subsignal file to the augmented data lists\n",
    "                    add_augmented(subsignal,i)\n",
    "                    \n",
    "                   # For 2 times augment the subsignal by adding background noise\n",
    "                    for e in range(2):\n",
    "                      \n",
    "                      signal_w_background = signal_with_background(signal_to_5_sec_duration(subsignal))\n",
    "                      add_augmented(signal_w_background,i)\n",
    "                \n",
    "                # If the index is odd then add the subsignal file to the audio data lists\n",
    "                else:\n",
    "                    add_audio(subsignal,i)\n",
    "        \n",
    "        # If the number of audio files for the bird is less than 3 then...            \n",
    "        else:\n",
    "            # Create a sub-signal list that includes the audio file divided into 5 second parts\n",
    "            subsignals = [signal[i:i+total_sample] for i in range(0, len(signal), total_sample)]\n",
    "            \n",
    "            # Iterate through the sub-signal list\n",
    "            for index, subsignal in enumerate(subsignals):\n",
    "                # If the index is even then...\n",
    "                if index % 2 == 0:\n",
    "                    # Create a pink noise and add it to augmented audio data lists\n",
    "                    signal_pink = signal_pinked(subsignal)\n",
    "                    add_augmented(signal_pink,i)\n",
    "                    \n",
    "                    # Add the subsignal file to the augmented data lists\n",
    "                    add_augmented(subsignal,i)\n",
    "                    \n",
    "                   # For 3 times augment the subsignal by adding background noise\n",
    "                    for e in range(3):\n",
    "                      \n",
    "                      signal_w_background = signal_with_background(signal_to_5_sec_duration(subsignal))\n",
    "                      add_augmented(signal_w_background,i)\n",
    "                \n",
    "                # If the index is odd then add the subsignal file to the audio data lists\n",
    "                else:\n",
    "                    add_audio(subsignal,i)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        \n",
    "        # If the length of the audio data lists is more than rows_per_file (750) then save the data into a numpy file as audio_data_X1, audio_data_X2, ...\n",
    "        if len(audio_data_X) >= rows_per_file:\n",
    "            # Convert the audio data lists to numpy arrays\n",
    "            audio_data_X_array_3D = np.array(audio_data_X[:rows_per_file])\n",
    "            # Extract the subset of data for this file\n",
    "            subset_data = audio_data_X_array_3D[:rows_per_file]\n",
    "            # Put the rest of the data back into the audio_data_X list\n",
    "            audio_data_X = audio_data_X[rows_per_file:]\n",
    "            # Generate the filename (audio_data_X1, audio_data_X2, ...)\n",
    "            filename = f'audio_data_X{file_index + 1}.npy'\n",
    "            file_index +=1\n",
    "            # Save the subset_data to the file\n",
    "            np.save(filename, subset_data)\n",
    "            \n",
    "        # If the length of the augmented audio data lists is more than rows_per_file (750) then save the data into a numpy file as augmented_data_X1, augmented_data_X2, ...    \n",
    "        if len(augmented_data_X) >= rows_per_file:\n",
    "            # Convert the audio data lists to numpy arrays\n",
    "            augmented_data_X_array_3D = np.array(augmented_data_X[:rows_per_file])\n",
    "            # Extract the subset of data for this file\n",
    "            subset_data = augmented_data_X_array_3D[:rows_per_file]\n",
    "            # Put the rest of the data back into the augmented_data_X list\n",
    "            augmented_data_X = augmented_data_X[rows_per_file:]\n",
    "            # Generate the filename (audio_data_X1, audio_data_X2, ...)\n",
    "            filename = f'augmented_data_X{augmented_index + 1}.npy'\n",
    "            augmented_index +=1\n",
    "            # Save the subset_data to the file\n",
    "            np.save(filename, subset_data)\n",
    "                \n",
    "\n",
    "# Save the remaining data into a numpy files.\n",
    "\n",
    "# Convert the audio data lists to numpy arrays\n",
    "audio_data_X_array_3D = np.array(audio_data_X[:rows_per_file])\n",
    "# Extract the subset of data for this file\n",
    "subset_data = audio_data_X_array_3D[:rows_per_file]\n",
    "# Generate the filename (audio_data_X1, audio_data_X2, ...)\n",
    "filename = f'audio_data_X{file_index + 1}.npy'\n",
    "file_index +=1\n",
    "# Save the subset_data to the file\n",
    "np.save(filename, subset_data)\n",
    "\n",
    "# Convert the audio data lists to numpy arrays\n",
    "augmented_data_X_array_3D = np.array(augmented_data_X[:rows_per_file])\n",
    "# Extract the subset of data for this file\n",
    "subset_data = augmented_data_X_array_3D[:rows_per_file]\n",
    "# Generate the filename (audio_data_X1, audio_data_X2, ...)\n",
    "filename = f'augmented_data_X{augmented_index + 1}.npy'\n",
    "augmented_index +=1\n",
    "# Save the subset_data to the file\n",
    "np.save(filename, subset_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T23:11:04.361693800Z",
     "start_time": "2023-12-09T23:11:04.317180Z"
    }
   },
   "id": "bd3580375295b682"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "412ac6e23f6ed308",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T19:09:19.214246300Z",
     "start_time": "2023-12-03T19:09:19.161685900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a54e29e18642f1cb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T23:11:00.319821400Z",
     "start_time": "2023-12-09T23:11:00.146309800Z"
    }
   },
   "outputs": [],
   "source": [
    "# The labels are converted to numbers and subtracted by 1\n",
    "# Original labels:  1, 2, 3, 4, 5, 6, 7, 8, 9, ... 264\n",
    "# New labels:       0, 1, 2, 3, 4, 5, 6, 7, 8, ... 263\n",
    "for i in range(len(audio_data_Y)):\n",
    "    audio_data_Y[i] = audio_data_Y[i] - 1\n",
    "\n",
    "for i in range(len(augmented_data_Y)):\n",
    "    augmented_data_Y[i] = augmented_data_Y[i] - 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b000d1c6ff8e5ea8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T23:11:01.460751600Z",
     "start_time": "2023-12-09T23:11:01.204763900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the labels into a csv file\n",
    "np.savetxt('audio_data_Y.csv',audio_data_Y , fmt='%d', delimiter=',')\n",
    "np.savetxt('augmented_data_Y.csv', augmented_data_Y, fmt='%d', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f91b96753607b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed5054430a46b1c",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-04T11:22:39.213732400Z",
     "start_time": "2023-12-04T11:22:31.514526700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62425383baeaa986",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T23:21:24.539437600Z",
     "start_time": "2023-12-09T23:21:24.523447500Z"
    }
   },
   "outputs": [],
   "source": [
    "# The audio files are loaded from the numpy files and each row will be saved into a separate numpy file\n",
    "def save_data_by_slices(loaded_array, labels, folder_path, rows_per_file = 750, next_id = 0):\n",
    "    \n",
    "    # Initialize the basic index for the file name\n",
    "    basic_index = 0  \n",
    "    if folder_path == 'augmented':\n",
    "      basic_index = rows_per_file * next_id\n",
    "    \n",
    "    # Check if the folder already exists\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "\n",
    "    # Iterate through the loaded array\n",
    "    for dataset_index, (array, label) in enumerate(zip(loaded_array, labels)):\n",
    "        \n",
    "      # Get the unique values of the label\n",
    "      label_values = np.unique(label)\n",
    "      \n",
    "      \n",
    "      \n",
    "      for label_value in label_values:\n",
    "          \n",
    "          # Save the entire 3D array with the same label value\n",
    "          file_path_array = os.path.join(folder_path, f'{label_value}_dataset{dataset_index + basic_index}_array.npy')\n",
    "          np.save(file_path_array, array)\n",
    "\n",
    "\n",
    "\n",
    "# Function to load each datset numpy files and then will use the save_data_by_slices function to save each row into a separate numpy file\n",
    "def load_and_save_data(base_name, num_files, all_labels, folder_name, rows_per_file = 750):\n",
    "\n",
    "   \n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    # Iterate through the files\n",
    "    for i in range(1, num_files + 1):\n",
    "        file_name = f'{base_name}{i}.npy'\n",
    "        loaded_array = np.load(file_name)\n",
    "        \n",
    "        save_data_by_slices(loaded_array, all_labels[((i-1) * rows_per_file) : (i * rows_per_file)],  folder_name, rows_per_file, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7053e9abe62ceb5e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T23:15:11.711966400Z",
     "start_time": "2023-12-09T23:15:11.466004500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# The audio labels are loaded from the csv files\n",
    "audio_data_Y = np.loadtxt(\"audio_data_Y.csv\", delimiter=',',dtype=int)\n",
    "augmented_data_Y = np.loadtxt(\"augmented_data_Y.csv\", delimiter=',',dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb06cc8a1c39229",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-09T23:15:15.087716100Z"
    }
   },
   "outputs": [],
   "source": [
    "# The audio files are loaded from the numpy files and each row will be saved into a separate numpy file in the data folder and augmented folder\n",
    "load_and_save_data('audio_data_X', 19, audio_data_Y, 'data',750)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac9e270458d7db",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "load_and_save_data('augmented_data_X', 35, augmented_data_Y, 'augmented',750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d532cdfb9e17cd9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T23:21:27.266005Z",
     "start_time": "2023-12-09T23:21:27.207891700Z"
    }
   },
   "outputs": [],
   "source": [
    "# The dataset folder is normalized (min-max scale) and the normalized data will be saved into the normalized folder\n",
    "# Each channel will be normalized separately\n",
    "def normalize_dataset(input_folder, output_folder):\n",
    "\n",
    "  # Initialize variables for min and max of each channel\n",
    "  min_channel_1 = float('inf')\n",
    "  min_channel_2 = float('inf')\n",
    "  min_channel_3 = float('inf')\n",
    "\n",
    "  max_channel_1 = float('-inf')\n",
    "  max_channel_2 = float('-inf')\n",
    "  max_channel_3 = float('-inf')\n",
    "\n",
    "  # Iterate through the files in the input folder\n",
    "  for filename in os.listdir(input_folder):\n",
    "      if filename.endswith('.npy'):\n",
    "          file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "          # Load the data from the current file\n",
    "          data = np.load(file_path)\n",
    "\n",
    "          # Find the min and max values for each channel\n",
    "          min_channel_1 = min(min_channel_1, data[ :, :, 0].min())\n",
    "          min_channel_2 = min(min_channel_2, data[ :, :, 1].min())\n",
    "          min_channel_3 = min(min_channel_3, data[ :, :, 2].min())\n",
    "\n",
    "          max_channel_1 = max(max_channel_1, data[ :, :, 0].max())\n",
    "          max_channel_2 = max(max_channel_2, data[ :, :, 1].max())\n",
    "          max_channel_3 = max(max_channel_3, data[ :, :, 2].max())\n",
    "\n",
    "  # Print the min and max values for each channel\n",
    "  print(\"Min values:\")\n",
    "  print(\"Channel 1:\", min_channel_1)\n",
    "  print(\"Channel 2:\", min_channel_2)\n",
    "  print(\"Channel 3:\", min_channel_3)\n",
    "\n",
    "  print(\"\\nMax values:\")\n",
    "  print(\"Channel 1:\", max_channel_1)\n",
    "  print(\"Channel 2:\", max_channel_2)\n",
    "  print(\"Channel 3:\", max_channel_3)\n",
    "    \n",
    "# Iterate through the files in the input folder\n",
    "  for filename in os.listdir(input_folder):\n",
    "      if filename.endswith('.npy'):\n",
    "          file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "          # Load the data from the current file\n",
    "          data = np.load(file_path)\n",
    "\n",
    "          # Normalize the data\n",
    "          normalized_data = (data - np.array([min_channel_1, min_channel_2, min_channel_3])) / \\\n",
    "                            np.array([max_channel_1 - min_channel_1, max_channel_2 - min_channel_2, max_channel_3 - min_channel_3])\n",
    "\n",
    "          # Save the normalized data to the output folder\n",
    "          output_path = os.path.join(output_folder, filename)\n",
    "          np.save(output_path, normalized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c12c8bacc2b3061",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T23:21:29.377705700Z",
     "start_time": "2023-12-09T23:21:29.296941600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a folder if it doesn't exist\n",
    "def create_folder(folder_path):\n",
    "  # Check if the folder already exists\n",
    "  if not os.path.exists(folder_path):\n",
    "      # If it doesn't exist, create the folder\n",
    "      os.makedirs(folder_path)\n",
    "      print(f\"Folder '{folder_path}' created successfully.\")\n",
    "  else:\n",
    "      print(f\"Folder '{folder_path}' already exists.\")\n",
    "\n",
    "\n",
    "# Function to split the dataset into train, test, and validation sets\n",
    "def dataset_split(data_folder, train_folder, test_folder, validation_folder, train_size, val_size ):\n",
    "\n",
    "  # Create train, test, and validation folders if they don't exist\n",
    "  for folder in [train_folder, test_folder, validation_folder]:\n",
    "      if not os.path.exists(folder):\n",
    "          os.makedirs(folder)\n",
    "\n",
    "  # Get a list of all .npy files in the data folder\n",
    "  npy_files = [file for file in os.listdir(data_folder) if file.endswith('.npy')]\n",
    "\n",
    "  # Shuffle the list of .npy files\n",
    "  random.shuffle(npy_files)\n",
    "\n",
    "  # Calculate the number of files for each split\n",
    "  total_files = len(npy_files)\n",
    "  train_split = int(train_size * total_files)\n",
    "  val_split = int(val_size * total_files)\n",
    "\n",
    "  # Split the files into train, test, and validation sets\n",
    "  train_files = npy_files[:train_split]\n",
    "  validation_files = npy_files[train_split:train_split + val_split]\n",
    "  test_files = npy_files[train_split + val_split:]\n",
    "\n",
    "  # Copy files to the respective folders\n",
    "  for file in train_files:\n",
    "      shutil.copy(os.path.join(data_folder, file), os.path.join(train_folder, file))\n",
    "\n",
    "  # Augmented data is not split into test and validation sets\n",
    "  if data_folder != 'augmented':\n",
    "\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(data_folder, file), os.path.join(test_folder, file))\n",
    "\n",
    "    for file in validation_files:\n",
    "        shutil.copy(os.path.join(data_folder, file), os.path.join(validation_folder, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0632956350e1f75",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "train_folder = 'train'\n",
    "test_folder = 'test'\n",
    "validation_folder = 'validation'\n",
    "\n",
    "create_folder(train_folder)\n",
    "create_folder(test_folder)\n",
    "create_folder(validation_folder)\n",
    "\n",
    "\n",
    "dataset_split(data_folder, train_folder, test_folder, validation_folder, 0, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0ed5c04fb2478e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T23:36:44.173266200Z",
     "start_time": "2023-12-09T23:30:50.083709400Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = 'augmented'\n",
    "dataset_split(data_folder, train_folder, test_folder, validation_folder, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd361402fc56d9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_folder = 'train'\n",
    "output_folder = 'train'\n",
    "\n",
    "normalize_dataset(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0278e606fc8ad3d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_folder = 'validation'\n",
    "output_folder = 'validation'\n",
    "\n",
    "normalize_dataset(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a819cdeae6bfbe9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_folder = 'test'\n",
    "output_folder = 'test'\n",
    "\n",
    "normalize_dataset(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974614bab8a847",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748e7b5288a0d4af",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-09T23:44:57.533477400Z",
     "start_time": "2023-12-09T23:44:57.519231800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to serialize data and labels and write to TFRecord file\n",
    "def _serialize_example(data, labels):\n",
    "    feature = {\n",
    "        'data': tf.train.Feature(float_list=tf.train.FloatList(value=data.flatten())),\n",
    "        'labels': tf.train.Feature(int64_list=tf.train.Int64List(value=int(labels))),\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "# Function to write TFRecord file\n",
    "def write_tfrecord(filename, dataset, labels):\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for data, label in zip(dataset, labels):\n",
    "            tf_example = _serialize_example(data, label)\n",
    "            writer.write(tf_example)\n",
    "\n",
    "# Function to parse TFRecord example\n",
    "def _parse_function(proto):\n",
    "    keys_to_features = {\n",
    "        'data': tf.io.FixedLenFeature([128 * 313 * 3], tf.float32),\n",
    "        'labels': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    parsed_features['data'] = tf.reshape(parsed_features['data'], (128, 313, 3))\n",
    "    return parsed_features['data'], parsed_features['labels']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e445eb26255f50c",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-09T23:44:57.548776400Z",
     "start_time": "2023-12-09T23:44:57.525480900Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Function to serialize data and labels and write to TFRecord file\n",
    "def _serialize_example(data, labels):\n",
    "    feature = {\n",
    "        'data': tf.train.Feature(float_list=tf.train.FloatList(value=data.flatten())),\n",
    "        'labels': tf.train.Feature(int64_list=tf.train.Int64List(value=[labels])),\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "# Function to append data to an existing TFRecord file without loading all records into memory\n",
    "def append_tfrecord(filename, new_data, new_labels):\n",
    "    temp_train_tfrecord_path = 'temp_dataset.tfrecord'\n",
    "\n",
    "    with tf.io.TFRecordWriter(temp_train_tfrecord_path) as writer:\n",
    "        # Write new records\n",
    "        for data, label in zip(new_data, new_labels):\n",
    "            tf_example = _serialize_example(data, label)\n",
    "            writer.write(tf_example)\n",
    "\n",
    "        # Copy existing records to the new file\n",
    "        for record in tf.data.TFRecordDataset(filename):\n",
    "            writer.write(record.numpy())\n",
    "\n",
    "    # Replace the original file with the new file\n",
    "    shutil.move(temp_train_tfrecord_path, filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd3053d4a6c7a79f",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T00:33:31.664149400Z",
     "start_time": "2023-12-10T00:33:31.630634Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to create a TensorFlow dataset from TFRecord files\n",
    "# The input folder is the folder that contains the numpy records files\n",
    "def save_dataset_into_tf(input_folder, tf_file_name, batch_size = 3000):\n",
    "\n",
    "  # The reference to the dataset\n",
    "  dataset = None\n",
    "  # The data and label lists\n",
    "  data = np.empty((0, 128, 313, 3), dtype=np.float32)\n",
    "  label = np.empty((0, ), dtype=np.int64)\n",
    "\n",
    "  batch_number = 0\n",
    "\n",
    "  # Iterate through the files in the input folder\n",
    "  for filename in os.listdir(input_folder):\n",
    "      if filename.endswith('.npy'):\n",
    "          file_path = os.path.join(input_folder, filename)\n",
    "          print(file_path)\n",
    "          \n",
    "          # Load the data from the current file\n",
    "          data = np.concatenate((data, np.load(file_path).reshape(1, 128, 313, 3)), axis=0)\n",
    "          \n",
    "          # Get the label from the file name\n",
    "          number = file_path.split('\\\\')[1].split('_')[-2]\n",
    "          label = np.concatenate((label, np.array([np.int64(number)])), axis=0)\n",
    "\n",
    "          batch_number += 1\n",
    "\n",
    "          # If the batch size is reached then save the data and label into a TFRecord file \n",
    "          if batch_number == batch_size:\n",
    "\n",
    "            if os.path.exists(tf_file_name):\n",
    "              # Append the new data to the existing TFRecord file\n",
    "              append_tfrecord(tf_file_name, data, label)\n",
    "            else:\n",
    "              # Write TFRecord files\n",
    "              write_tfrecord(tf_file_name, data, label)\n",
    "              # Create TensorFlow datasets for training and validation from TFRecord files\n",
    "              dataset = tf.data.TFRecordDataset(tf_file_name).map(_parse_function)\n",
    "                \n",
    "            batch_number = 0\n",
    "            data = np.empty((0, 128, 313, 3), dtype=np.float32)\n",
    "            label = np.empty((0, ), dtype=np.int64)\n",
    "              \n",
    "\n",
    "  # Save the remaining data into a TFRecord file if the data and label lists are not empty\n",
    "  if batch_number != 0:\n",
    "      \n",
    "    if os.path.exists(tf_file_name):\n",
    "      # Append the new data to the existing TFRecord file\n",
    "      append_tfrecord(tf_file_name, data, label)\n",
    "    else:\n",
    "      # Write TFRecord files\n",
    "      write_tfrecord(tf_file_name, data, label)\n",
    "      # Create TensorFlow datasets for training and validation from TFRecord files\n",
    "      dataset = tf.data.TFRecordDataset(tf_file_name).map(_parse_function)\n",
    "          \n",
    "  return dataset\n",
    "\n",
    "# Function to create a TFRecord files if it doesn't exist and load the data from the TFRecord file if it exists\n",
    "def create_tf_dataset(input_folder, file_name):\n",
    "  dataset = None\n",
    "  # Check if the file already exists\n",
    "  if os.path.exists(file_name):\n",
    "    dataset = tf.data.TFRecordDataset(file_name).map(_parse_function)\n",
    "  else:\n",
    "    dataset = save_dataset_into_tf('validation',file_name)\n",
    "\n",
    "  return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5da1345-7b73-476d-a08d-1ad9ee31560b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-09T23:50:43.397795Z",
     "start_time": "2023-12-09T23:50:43.336794200Z"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle the dataset folder files by add a random number to the file name (renaming the filenames)\n",
    "def dataset_shuffle(folder_path):\n",
    "\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    id = 0\n",
    "\n",
    "    # Iterate through each file and rename it\n",
    "    for file_name in files:\n",
    "        # Generate a random number between 0 and 10000\n",
    "        random_number = random.randint(0, 10000)\n",
    "\n",
    "        # Extract the index from the original file name\n",
    "        file_index = file_name.split('_')[0]\n",
    "\n",
    "        # Create the new file name\n",
    "        new_file_name = f\"{random_number}_{file_index}_dataset{ id }.npy\"\n",
    "        \n",
    "        id+=1\n",
    "\n",
    "        # Construct the full paths\n",
    "        old_path = os.path.join(folder_path, file_name)\n",
    "        new_path = os.path.join(folder_path, new_file_name)\n",
    "\n",
    "        # Rename the file\n",
    "        os.rename(old_path, new_path)\n",
    "\n",
    "    print(\"File renaming completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac2ba3fb-9af3-44b9-aff3-75055588690f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-09T23:50:45.389977700Z",
     "start_time": "2023-12-09T23:50:45.311459200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d55741-8b7a-4de2-a6f9-f46f9303445a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_shuffle('train')\n",
    "dataset_shuffle('test')\n",
    "dataset_shuffle('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ee4ae629a2e33",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset = save_dataset_into_tf('validation','val_dataset.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a28965b50fbd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\\2845_169_dataset6532.npy\n",
      "train\\2845_183_dataset8056.npy\n",
      "train\\2845_202_dataset9951.npy\n",
      "train\\2846_120_dataset1757.npy\n",
      "train\\2846_141_dataset4224.npy\n",
      "train\\2846_206_dataset10278.npy\n",
      "train\\2846_50_dataset19395.npy\n",
      "train\\2846_61_dataset20516.npy\n",
      "train\\2848_149_dataset5109.npy\n"
     ]
    }
   ],
   "source": [
    " train_dataset = save_dataset_into_tf('train','train_dataset.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986380b694f899fd",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T00:32:44.858486Z",
     "start_time": "2023-12-10T00:32:44.853487900Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = save_dataset_into_tf('test','test_dataset.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a713fd7faac20",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
