{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HelaOcNe0A7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4a7f13-254d-4d49-8ef0-5779a077c49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import shutil\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "gc.enable()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubCUdiX8DTBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download all the necessary files for the BirdCLEF2023 competition\n",
        "\n",
        "\n",
        "! gdown  1csRtTkSjkr4zi02A7hh92Vd3-q8bRu9U # https://drive.google.com/file/d/1csRtTkSjkr4zi02A7hh92Vd3-q8bRu9U/view?usp=share_link\n",
        "\n",
        "! gdown  171Dt710QatK8_fpGOowyOCq0--8iKZNi # https://drive.google.com/file/d/171Dt710QatK8_fpGOowyOCq0--8iKZNi/view?usp=share_link\n",
        "\n",
        "! gdown  1QZtXYvPpZ9PgvWhS7AjPiKCWmSSx2N3_ # https://drive.google.com/file/d/1QZtXYvPpZ9PgvWhS7AjPiKCWmSSx2N3_/view?usp=share_link\n",
        "\n",
        "! gdown  1wJOwvbRRhV7-jbCunlT6YI_yuPpRu8mn # https://drive.google.com/file/d/1wJOwvbRRhV7-jbCunlT6YI_yuPpRu8mn/view?usp=share_link\n",
        "\n",
        "! gdown  1cbB3f6kFGUshonoGIa9C4tUQdZm1UYsY # https://drive.google.com/file/d/1cbB3f6kFGUshonoGIa9C4tUQdZm1UYsY/view?usp=share_link\n",
        "\n",
        "! gdown  1fhEzrtHzjT2J_LZM-vIOemXjzmKtnxXc # https://drive.google.com/file/d/1fhEzrtHzjT2J_LZM-vIOemXjzmKtnxXc/view?usp=drive_link"
      ],
      "metadata": {
        "id": "B3MjhPdi0FKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6dba5ec-52de-4993-e5ea-16dccaa0e2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1csRtTkSjkr4zi02A7hh92Vd3-q8bRu9U\n",
            "To: /content/audio_bird_name.csv\n",
            "100% 148k/148k [00:00<00:00, 123MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=171Dt710QatK8_fpGOowyOCq0--8iKZNi\n",
            "To: /content/audio_data_Y.csv\n",
            "100% 76.7k/76.7k [00:00<00:00, 46.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QZtXYvPpZ9PgvWhS7AjPiKCWmSSx2N3_\n",
            "To: /content/eBird_Taxonomy_v2021.csv\n",
            "100% 2.01M/2.01M [00:00<00:00, 18.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wJOwvbRRhV7-jbCunlT6YI_yuPpRu8mn\n",
            "To: /content/sample_submission.csv\n",
            "100% 3.74k/3.74k [00:00<00:00, 17.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cbB3f6kFGUshonoGIa9C4tUQdZm1UYsY\n",
            "To: /content/train_metadata.csv\n",
            "100% 3.60M/3.60M [00:00<00:00, 236MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fhEzrtHzjT2J_LZM-vIOemXjzmKtnxXc\n",
            "To: /content/augmented_data_Y_50.csv\n",
            "100% 24.4k/24.4k [00:00<00:00, 54.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the splitted X audio data from the Google Drive which has been saved.\n",
        "# This jupyter code generated those files: https://colab.research.google.com/drive/14WKdPt7H-psYb-hjG1ftCPeH9wevuJ1A\n",
        "\n",
        "def download_files(file_ids, prefix, file_type=\"npy\"):\n",
        "    for i, file_id in enumerate(file_ids):\n",
        "        destination = f'{prefix}_X{i + 1}.{file_type}'\n",
        "        url = f'https://drive.google.com/uc?id={file_id}'\n",
        "        gdown.download(url, destination, quiet=False)\n",
        "\n",
        "\n",
        "# Define the Google Drive file ID\n",
        "file_id_audio = [\n",
        "            '1gSu-EkrSYmjxYg18DLKP9VcQs--QqQ0l',\n",
        "           '1ZLSaUMdrTLjZYk-VUKHALkJNqEHOMUQb',\n",
        "           '1tW10PTV8wWG0LNjI7tQCxodwDJBofWxS',\n",
        "           '1s32-Ou0uexEoej3LWdvV3c4sExb7bdM7',\n",
        "           '1cyExp5s0eNlw3o23vXi50C6eLCFzp-Md',\n",
        "           '18fLcutxetAPlXIsjO5E8vt5Z96p91uVo',\n",
        "           '1hUw5dfMJf_xp0V8YK8iUedMLETYi0Box',\n",
        "           '15t09xUyAGCVfTPJIEFTw2TWlxRk55TJB',\n",
        "           '1QtPz9aML3FkflFE9kf4fggQaYi2P_vV7',\n",
        "           '1x_H-RrVesqHbx0CnH0ee2T-W2NnHr-so',\n",
        "           ]\n",
        "\n",
        "# Define the Google Drive file ID\n",
        "file_id_augmented = [\n",
        "            '1wBIZLPuCIbEGpVBntP3wEVe_qx1TXN9f', # https://drive.google.com/file/d/1wBIZLPuCIbEGpVBntP3wEVe_qx1TXN9f/view?usp=drive_link\n",
        "            '1DT8bThsLgNRy3S0fEiKeJciG_PWYeVXS', # https://drive.google.com/file/d/1DT8bThsLgNRy3S0fEiKeJciG_PWYeVXS/view?usp=drive_link\n",
        "            '15VMweJEogukNmmddHWWDP7Xh24kuirKf', # https://drive.google.com/file/d/15VMweJEogukNmmddHWWDP7Xh24kuirKf/view?usp=drive_link\n",
        "            '1biiGgxvu_nOK1Y92DhjqaHsK9wiyAJkX', # https://drive.google.com/file/d/1biiGgxvu_nOK1Y92DhjqaHsK9wiyAJkX/view?usp=drive_link\n",
        "\n",
        "            ]\n",
        "\n",
        "\n",
        "# Download audio data\n",
        "download_files(file_id_audio, \"audio_data\")\n",
        "\n",
        "# Download augmented data\n",
        "download_files(file_id_augmented, \"augmented_data\")"
      ],
      "metadata": {
        "id": "bqSO65cT0HaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de554b94-859a-4f7e-a0d6-8c5cf0503bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gSu-EkrSYmjxYg18DLKP9VcQs--QqQ0l\n",
            "To: /content/audio_data_X1.npy\n",
            "100%|██████████| 272M/272M [00:02<00:00, 104MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZLSaUMdrTLjZYk-VUKHALkJNqEHOMUQb\n",
            "To: /content/audio_data_X2.npy\n",
            "100%|██████████| 272M/272M [00:05<00:00, 51.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tW10PTV8wWG0LNjI7tQCxodwDJBofWxS\n",
            "To: /content/audio_data_X3.npy\n",
            "100%|██████████| 272M/272M [00:04<00:00, 61.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1s32-Ou0uexEoej3LWdvV3c4sExb7bdM7\n",
            "To: /content/audio_data_X4.npy\n",
            "100%|██████████| 272M/272M [00:02<00:00, 104MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cyExp5s0eNlw3o23vXi50C6eLCFzp-Md\n",
            "To: /content/audio_data_X5.npy\n",
            "100%|██████████| 272M/272M [00:02<00:00, 97.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18fLcutxetAPlXIsjO5E8vt5Z96p91uVo\n",
            "To: /content/audio_data_X6.npy\n",
            "100%|██████████| 272M/272M [00:02<00:00, 106MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hUw5dfMJf_xp0V8YK8iUedMLETYi0Box\n",
            "To: /content/audio_data_X7.npy\n",
            "100%|██████████| 272M/272M [00:09<00:00, 27.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15t09xUyAGCVfTPJIEFTw2TWlxRk55TJB\n",
            "To: /content/audio_data_X8.npy\n",
            "100%|██████████| 272M/272M [00:04<00:00, 63.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QtPz9aML3FkflFE9kf4fggQaYi2P_vV7\n",
            "To: /content/audio_data_X9.npy\n",
            "100%|██████████| 272M/272M [00:04<00:00, 56.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1x_H-RrVesqHbx0CnH0ee2T-W2NnHr-so\n",
            "To: /content/audio_data_X10.npy\n",
            "100%|██████████| 263M/263M [00:04<00:00, 60.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wBIZLPuCIbEGpVBntP3wEVe_qx1TXN9f\n",
            "To: /content/augmented_data_X1.npy\n",
            "100%|██████████| 272M/272M [00:04<00:00, 64.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DT8bThsLgNRy3S0fEiKeJciG_PWYeVXS\n",
            "To: /content/augmented_data_X2.npy\n",
            "100%|██████████| 272M/272M [00:02<00:00, 95.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15VMweJEogukNmmddHWWDP7Xh24kuirKf\n",
            "To: /content/augmented_data_X3.npy\n",
            "100%|██████████| 272M/272M [00:04<00:00, 57.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1biiGgxvu_nOK1Y92DhjqaHsK9wiyAJkX\n",
            "To: /content/augmented_data_X4.npy\n",
            "100%|██████████| 26.8M/26.8M [00:00<00:00, 73.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and concatenate data from files\n",
        "def load_and_concatenate_data(base_name, num_files):\n",
        "    concatenated_data = None\n",
        "    for i in range(1, num_files + 1):\n",
        "        file_name = f'{base_name}{i}.npy'\n",
        "        loaded_array = np.load(file_name)\n",
        "        if concatenated_data is None:\n",
        "            concatenated_data = loaded_array\n",
        "        else:\n",
        "            concatenated_data = np.concatenate((concatenated_data, loaded_array), axis=0)\n",
        "    return concatenated_data\n",
        "\n",
        "# Load and concatenate audio data\n",
        "audio_data_X = load_and_concatenate_data('audio_data_X', 10) # len(file_id_audio)\n",
        "augmented_data_X = load_and_concatenate_data('augmented_data_X', 4) # len(file_id_augmented)\n",
        "\n"
      ],
      "metadata": {
        "id": "sH7u6tYW0JuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Y (the id column, int data type) and the Y_bird_name (the name column)\n",
        "audio_data_Y = np.loadtxt(\"/content/audio_data_Y.csv\", delimiter=',',dtype=int)\n",
        "augmented_data_Y = np.loadtxt(\"/content/augmented_data_Y_50.csv\", delimiter=',',dtype=int)\n",
        "audio_data_Y -= 1\n",
        "augmented_data_Y -= 1\n",
        "\n",
        "# audio_data_Y = np.concatenate((audio_data_Y, augmented_data_Y), axis=0)\n",
        "# del augmented_data_Y\n",
        "\n",
        "audio_data_Y_bird_name = np.genfromtxt(\"/content/audio_bird_name.csv\", delimiter=',', dtype='str').astype('object')\n",
        "\n",
        "# Generate an array of IDs for each bird from 1 to number of the unique birds\n",
        "ids = np.arange(0, len(np.unique(audio_data_Y_bird_name)))\n",
        "# Add the ID column as a new dimension (column)\n",
        "audio_data_Y_unique_bird_name_with_id = np.column_stack((ids, np.unique(audio_data_Y_bird_name)))\n",
        "\n",
        "# The unique bird that contains each bird with ID\n",
        "print(audio_data_Y_unique_bird_name_with_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NteVbBV0Lbp",
        "outputId": "27d94d2e-8d3d-45cd-b021-6fbeb2af5d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 'abethr1']\n",
            " [1 'abhori1']\n",
            " [2 'abythr1']\n",
            " [3 'afbfly1']\n",
            " [4 'afdfly1']\n",
            " [5 'afecuc1']\n",
            " [6 'affeag1']\n",
            " [7 'afgfly1']\n",
            " [8 'afghor1']\n",
            " [9 'afmdov1']\n",
            " [10 'afpfly1']\n",
            " [11 'afpkin1']\n",
            " [12 'afpwag1']\n",
            " [13 'afrgos1']\n",
            " [14 'afrgrp1']\n",
            " [15 'afrjac1']\n",
            " [16 'afrthr1']\n",
            " [17 'amesun2']\n",
            " [18 'augbuz1']\n",
            " [19 'bagwea1']\n",
            " [20 'barswa']\n",
            " [21 'bawhor2']\n",
            " [22 'bawman1']\n",
            " [23 'bcbeat1']\n",
            " [24 'beasun2']\n",
            " [25 'bkctch1']\n",
            " [26 'bkfruw1']\n",
            " [27 'blacra1']\n",
            " [28 'blacuc1']\n",
            " [29 'blakit1']\n",
            " [30 'blaplo1']\n",
            " [31 'blbpuf2']\n",
            " [32 'blcapa2']\n",
            " [33 'blfbus1']\n",
            " [34 'blhgon1']\n",
            " [35 'blhher1']\n",
            " [36 'blksaw1']\n",
            " [37 'blnmou1']\n",
            " [38 'blnwea1']\n",
            " [39 'bltapa1']\n",
            " [40 'bltbar1']\n",
            " [41 'bltori1']\n",
            " [42 'blwlap1']\n",
            " [43 'brcale1']\n",
            " [44 'brcsta1']\n",
            " [45 'brctch1']\n",
            " [46 'brcwea1']\n",
            " [47 'brican1']\n",
            " [48 'brobab1']\n",
            " [49 'broman1']\n",
            " [50 'brosun1']\n",
            " [51 'brrwhe3']\n",
            " [52 'brtcha1']\n",
            " [53 'brubru1']\n",
            " [54 'brwwar1']\n",
            " [55 'bswdov1']\n",
            " [56 'btweye2']\n",
            " [57 'bubwar2']\n",
            " [58 'butapa1']\n",
            " [59 'cabgre1']\n",
            " [60 'carcha1']\n",
            " [61 'carwoo1']\n",
            " [62 'categr']\n",
            " [63 'ccbeat1']\n",
            " [64 'chespa1']\n",
            " [65 'chewea1']\n",
            " [66 'chibat1']\n",
            " [67 'chtapa3']\n",
            " [68 'chucis1']\n",
            " [69 'cibwar1']\n",
            " [70 'cohmar1']\n",
            " [71 'colsun2']\n",
            " [72 'combul2']\n",
            " [73 'combuz1']\n",
            " [74 'comsan']\n",
            " [75 'crefra2']\n",
            " [76 'crheag1']\n",
            " [77 'crohor1']\n",
            " [78 'darbar1']\n",
            " [79 'darter3']\n",
            " [80 'didcuc1']\n",
            " [81 'dotbar1']\n",
            " [82 'dutdov1']\n",
            " [83 'easmog1']\n",
            " [84 'eaywag1']\n",
            " [85 'edcsun3']\n",
            " [86 'egygoo']\n",
            " [87 'equaka1']\n",
            " [88 'eswdov1']\n",
            " [89 'eubeat1']\n",
            " [90 'fatrav1']\n",
            " [91 'fatwid1']\n",
            " [92 'fislov1']\n",
            " [93 'fotdro5']\n",
            " [94 'gabgos2']\n",
            " [95 'gargan']\n",
            " [96 'gbesta1']\n",
            " [97 'gnbcam2']\n",
            " [98 'gnhsun1']\n",
            " [99 'gobbun1']\n",
            " [100 'gobsta5']\n",
            " [101 'gobwea1']\n",
            " [102 'golher1']\n",
            " [103 'grbcam1']\n",
            " [104 'grccra1']\n",
            " [105 'grecor']\n",
            " [106 'greegr']\n",
            " [107 'grewoo2']\n",
            " [108 'grwpyt1']\n",
            " [109 'gryapa1']\n",
            " [110 'grywrw1']\n",
            " [111 'gybfis1']\n",
            " [112 'gycwar3']\n",
            " [113 'gyhbus1']\n",
            " [114 'gyhkin1']\n",
            " [115 'gyhneg1']\n",
            " [116 'gyhspa1']\n",
            " [117 'gytbar1']\n",
            " [118 'hadibi1']\n",
            " [119 'hamerk1']\n",
            " [120 'hartur1']\n",
            " [121 'helgui']\n",
            " [122 'hipbab1']\n",
            " [123 'hoopoe']\n",
            " [124 'huncis1']\n",
            " [125 'hunsun2']\n",
            " [126 'joygre1']\n",
            " [127 'kerspa2']\n",
            " [128 'klacuc1']\n",
            " [129 'kvbsun1']\n",
            " [130 'laudov1']\n",
            " [131 'lawgol']\n",
            " [132 'lesmaw1']\n",
            " [133 'lessts1']\n",
            " [134 'libeat1']\n",
            " [135 'litegr']\n",
            " [136 'litswi1']\n",
            " [137 'litwea1']\n",
            " [138 'loceag1']\n",
            " [139 'lotcor1']\n",
            " [140 'lotlap1']\n",
            " [141 'luebus1']\n",
            " [142 'mabeat1']\n",
            " [143 'macshr1']\n",
            " [144 'malkin1']\n",
            " [145 'marsto1']\n",
            " [146 'marsun2']\n",
            " [147 'mcptit1']\n",
            " [148 'meypar1']\n",
            " [149 'moccha1']\n",
            " [150 'mouwag1']\n",
            " [151 'ndcsun2']\n",
            " [152 'nobfly1']\n",
            " [153 'norbro1']\n",
            " [154 'norcro1']\n",
            " [155 'norfis1']\n",
            " [156 'norpuf1']\n",
            " [157 'nubwoo1']\n",
            " [158 'pabspa1']\n",
            " [159 'palfly2']\n",
            " [160 'palpri1']\n",
            " [161 'piecro1']\n",
            " [162 'piekin1']\n",
            " [163 'pitwhy']\n",
            " [164 'purgre2']\n",
            " [165 'pygbat1']\n",
            " [166 'quailf1']\n",
            " [167 'ratcis1']\n",
            " [168 'raybar1']\n",
            " [169 'rbsrob1']\n",
            " [170 'rebfir2']\n",
            " [171 'rebhor1']\n",
            " [172 'reboxp1']\n",
            " [173 'reccor']\n",
            " [174 'reccuc1']\n",
            " [175 'reedov1']\n",
            " [176 'refbar2']\n",
            " [177 'refcro1']\n",
            " [178 'reftin1']\n",
            " [179 'refwar2']\n",
            " [180 'rehblu1']\n",
            " [181 'rehwea1']\n",
            " [182 'reisee2']\n",
            " [183 'rerswa1']\n",
            " [184 'rewsta1']\n",
            " [185 'rindov']\n",
            " [186 'rocmar2']\n",
            " [187 'rostur1']\n",
            " [188 'ruegls1']\n",
            " [189 'rufcha2']\n",
            " [190 'sacibi2']\n",
            " [191 'sccsun2']\n",
            " [192 'scrcha1']\n",
            " [193 'scthon1']\n",
            " [194 'shesta1']\n",
            " [195 'sichor1']\n",
            " [196 'sincis1']\n",
            " [197 'slbgre1']\n",
            " [198 'slcbou1']\n",
            " [199 'sltnig1']\n",
            " [200 'sobfly1']\n",
            " [201 'somgre1']\n",
            " [202 'somtit4']\n",
            " [203 'soucit1']\n",
            " [204 'soufis1']\n",
            " [205 'spemou2']\n",
            " [206 'spepig1']\n",
            " [207 'spewea1']\n",
            " [208 'spfbar1']\n",
            " [209 'spfwea1']\n",
            " [210 'spmthr1']\n",
            " [211 'spwlap1']\n",
            " [212 'squher1']\n",
            " [213 'strher']\n",
            " [214 'strsee1']\n",
            " [215 'stusta1']\n",
            " [216 'subbus1']\n",
            " [217 'supsta1']\n",
            " [218 'tacsun1']\n",
            " [219 'tafpri1']\n",
            " [220 'tamdov1']\n",
            " [221 'thrnig1']\n",
            " [222 'trobou1']\n",
            " [223 'varsun2']\n",
            " [224 'vibsta2']\n",
            " [225 'vilwea1']\n",
            " [226 'vimwea1']\n",
            " [227 'walsta1']\n",
            " [228 'wbgbir1']\n",
            " [229 'wbrcha2']\n",
            " [230 'wbswea1']\n",
            " [231 'wfbeat1']\n",
            " [232 'whbcan1']\n",
            " [233 'whbcou1']\n",
            " [234 'whbcro2']\n",
            " [235 'whbtit5']\n",
            " [236 'whbwea1']\n",
            " [237 'whbwhe3']\n",
            " [238 'whcpri2']\n",
            " [239 'whctur2']\n",
            " [240 'wheslf1']\n",
            " [241 'whhsaw1']\n",
            " [242 'whihel1']\n",
            " [243 'whrshr1']\n",
            " [244 'witswa1']\n",
            " [245 'wlwwar']\n",
            " [246 'wookin1']\n",
            " [247 'woosan']\n",
            " [248 'wtbeat1']\n",
            " [249 'yebapa1']\n",
            " [250 'yebbar1']\n",
            " [251 'yebduc1']\n",
            " [252 'yebere1']\n",
            " [253 'yebgre1']\n",
            " [254 'yebsto1']\n",
            " [255 'yeccan1']\n",
            " [256 'yefcan']\n",
            " [257 'yelbis1']\n",
            " [258 'yenspu1']\n",
            " [259 'yertin1']\n",
            " [260 'yesbar1']\n",
            " [261 'yespet1']\n",
            " [262 'yetgre1']\n",
            " [263 'yewgre1']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the unique values and their frequencies\n",
        "unique_bird, counts = np.unique(np.concatenate((audio_data_Y, augmented_data_Y), axis=0), return_counts=True)\n",
        "plt.figure(figsize=(50, 30))\n",
        "\n",
        "# Create a bar plot (histogram)\n",
        "plt.bar(audio_data_Y_unique_bird_name_with_id[:,1], counts, width=0.3)\n",
        "\n",
        "# Set labels for the axes\n",
        "plt.xlabel('Unique Birds', fontsize=30)\n",
        "plt.ylabel('The number of audio for the birds', fontsize=30)\n",
        "plt.xticks(rotation=90)\n",
        "yticks_positions = np.append(np.arange(0, 100, 10),np.arange(100, max(counts) + 1, 50))  # Adjust the step (5) as needed\n",
        "plt.yticks(yticks_positions, fontsize=20)\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n6UBlMcq0NZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_percent = 0.4\n",
        "validation_index = len(audio_data_Y) - int(validation_percent * (len(audio_data_Y) + len(augmented_data_Y)))\n",
        "# validation_index = (len(audio_data_Y) + len(augmented_data_Y)) - validation_size\n",
        "\n",
        "permutation = np.random.permutation(len(audio_data_Y))\n",
        "\n",
        "audio_data_X = audio_data_X[permutation]\n",
        "audio_data_Y = audio_data_Y[permutation]\n",
        "\n",
        "\n",
        "permutation = np.random.permutation(len(augmented_data_Y))\n",
        "\n",
        "augmented_data_X = augmented_data_X[permutation]\n",
        "augmented_data_Y = augmented_data_Y[permutation]\n"
      ],
      "metadata": {
        "id": "yAxsSoNYlY3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate((augmented_data_X, audio_data_X[:validation_index]), axis=0)\n",
        "y_train = np.concatenate((augmented_data_Y, audio_data_Y[:validation_index]), axis=0)\n",
        "\n",
        "X_validation =  audio_data_X[validation_index:]\n",
        "y_validation =  audio_data_Y[validation_index:]\n",
        "\n",
        "X_test = X_validation[(len(X_validation)//2):]\n",
        "y_test = y_validation[(len(y_validation)//2):]\n",
        "\n",
        "X_validation = X_validation[:(len(X_validation)//2)]\n",
        "y_validation = y_validation[:(len(y_validation)//2)]\n",
        "\n",
        "\n",
        "permutation = np.random.permutation(len(y_train))\n",
        "\n",
        "X_train = X_train[permutation]\n",
        "y_train = y_train[permutation]\n",
        "\n",
        "augmented_data_Y.shape\n",
        "\n",
        "del augmented_data_X\n",
        "del augmented_data_Y\n",
        "del audio_data_X\n",
        "del audio_data_Y"
      ],
      "metadata": {
        "id": "tk7hAFAxpxhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_value_train, max_value_train = np.min(X_train), np.max(X_train)\n",
        "min_value_test, max_value_test = np.min(X_test), np.max(X_test)\n",
        "min_value_validation, max_value_validation = np.min(X_validation), np.max(X_validation)\n",
        "\n",
        "\n",
        "X_train = (X_train - min_value_train) / (max_value_train - min_value_train)\n",
        "X_test = (X_test - min_value_test) / (max_value_test - min_value_test)\n",
        "X_validation = (X_validation - min_value_validation) / (max_value_validation - min_value_validation)\n",
        "\n",
        "X_train= X_train.reshape(-1,128,313,1)\n",
        "X_test= X_test.reshape(-1,128,313,1)\n",
        "X_validation= X_validation.reshape(-1,128,313,1)\n"
      ],
      "metadata": {
        "id": "YRMVfOZTy-hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BBD8go_ENZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape):\n",
        "  \"\"\"Generates CNN model\n",
        "\n",
        "  :param input_shape (tuple): Shape of input set\n",
        "  :return model: CNN model\n",
        "  \"\"\"\n",
        "\n",
        "  # build network topology\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # 1st conv layer\n",
        "  model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "  model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "  # 2nd conv layer\n",
        "  model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "  model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "  # flatten output and feed it into dense layer\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(64, activation='relu',kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "  model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "  # output layer\n",
        "  model.add(keras.layers.Dense(264, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "HXwbLn-K2VNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create network\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "model = build_model(input_shape)\n",
        "\n",
        "# compile model\n",
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRMzTqDe-cB_",
        "outputId": "554d55c8-e87c-406e-fa59-11cc182d0e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 311, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 63, 156, 32)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 63, 156, 32)       128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 154, 32)       9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 31, 77, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 31, 77, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 76384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4888640   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 264)               17160     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4915624 (18.75 MB)\n",
            "Trainable params: 4915496 (18.75 MB)\n",
            "Non-trainable params: 128 (512.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 20\n",
        "early_stopping=EarlyStopping(patience=patience, verbose=2)\n",
        "checkpointer=ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, verbose=2)"
      ],
      "metadata": {
        "id": "J8f9ihHBORWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(X_train[:], y_train[:],\n",
        "                    validation_data=(X_validation[:], y_validation[:]),\n",
        "                    batch_size=128,\n",
        "                    epochs=1000,\n",
        "                    callbacks=[checkpointer, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PIS8WI2L-rmP",
        "outputId": "ffb2e8d1-d0e1-4b1c-eb85-2126aebbb9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "105/105 [==============================] - ETA: 0s - loss: 5.6798 - accuracy: 0.0200\n",
            "Epoch 1: val_loss improved from inf to 5.79405, saving model to weights.hdf5\n",
            "105/105 [==============================] - 30s 153ms/step - loss: 5.6798 - accuracy: 0.0200 - val_loss: 5.7941 - val_accuracy: 0.0027\n",
            "Epoch 2/1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104/105 [============================>.] - ETA: 0s - loss: 5.3736 - accuracy: 0.0493\n",
            "Epoch 2: val_loss did not improve from 5.79405\n",
            "105/105 [==============================] - 11s 109ms/step - loss: 5.3737 - accuracy: 0.0492 - val_loss: 6.1281 - val_accuracy: 0.0027\n",
            "Epoch 3/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 5.0190 - accuracy: 0.0979\n",
            "Epoch 3: val_loss did not improve from 5.79405\n",
            "105/105 [==============================] - 11s 105ms/step - loss: 5.0185 - accuracy: 0.0980 - val_loss: 6.2072 - val_accuracy: 0.0029\n",
            "Epoch 4/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 4.5652 - accuracy: 0.1552\n",
            "Epoch 4: val_loss did not improve from 5.79405\n",
            "105/105 [==============================] - 12s 111ms/step - loss: 4.5650 - accuracy: 0.1552 - val_loss: 5.8420 - val_accuracy: 0.0491\n",
            "Epoch 5/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 4.1280 - accuracy: 0.2183\n",
            "Epoch 5: val_loss improved from 5.79405 to 5.42445, saving model to weights.hdf5\n",
            "105/105 [==============================] - 12s 112ms/step - loss: 4.1274 - accuracy: 0.2183 - val_loss: 5.4245 - val_accuracy: 0.0768\n",
            "Epoch 6/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 3.7251 - accuracy: 0.2780\n",
            "Epoch 6: val_loss improved from 5.42445 to 4.86111, saving model to weights.hdf5\n",
            "105/105 [==============================] - 11s 110ms/step - loss: 3.7250 - accuracy: 0.2780 - val_loss: 4.8611 - val_accuracy: 0.1347\n",
            "Epoch 7/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 3.3318 - accuracy: 0.3353\n",
            "Epoch 7: val_loss improved from 4.86111 to 4.69327, saving model to weights.hdf5\n",
            "105/105 [==============================] - 12s 111ms/step - loss: 3.3320 - accuracy: 0.3353 - val_loss: 4.6933 - val_accuracy: 0.1639\n",
            "Epoch 8/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 2.9877 - accuracy: 0.3914\n",
            "Epoch 8: val_loss improved from 4.69327 to 4.58492, saving model to weights.hdf5\n",
            "105/105 [==============================] - 12s 115ms/step - loss: 2.9870 - accuracy: 0.3916 - val_loss: 4.5849 - val_accuracy: 0.1853\n",
            "Epoch 9/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 2.6539 - accuracy: 0.4436\n",
            "Epoch 9: val_loss improved from 4.58492 to 4.47573, saving model to weights.hdf5\n",
            "105/105 [==============================] - 12s 116ms/step - loss: 2.6544 - accuracy: 0.4435 - val_loss: 4.4757 - val_accuracy: 0.2015\n",
            "Epoch 10/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 2.3637 - accuracy: 0.4966\n",
            "Epoch 10: val_loss improved from 4.47573 to 4.38160, saving model to weights.hdf5\n",
            "105/105 [==============================] - 12s 114ms/step - loss: 2.3635 - accuracy: 0.4967 - val_loss: 4.3816 - val_accuracy: 0.2137\n",
            "Epoch 11/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 2.1280 - accuracy: 0.5404\n",
            "Epoch 11: val_loss improved from 4.38160 to 4.35153, saving model to weights.hdf5\n",
            "105/105 [==============================] - 12s 111ms/step - loss: 2.1269 - accuracy: 0.5407 - val_loss: 4.3515 - val_accuracy: 0.2148\n",
            "Epoch 12/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.8731 - accuracy: 0.5946\n",
            "Epoch 12: val_loss improved from 4.35153 to 4.30161, saving model to weights.hdf5\n",
            "105/105 [==============================] - 12s 115ms/step - loss: 1.8738 - accuracy: 0.5944 - val_loss: 4.3016 - val_accuracy: 0.2229\n",
            "Epoch 13/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.6982 - accuracy: 0.6321\n",
            "Epoch 13: val_loss improved from 4.30161 to 4.29369, saving model to weights.hdf5\n",
            "105/105 [==============================] - 12s 114ms/step - loss: 1.6978 - accuracy: 0.6321 - val_loss: 4.2937 - val_accuracy: 0.2349\n",
            "Epoch 14/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.5128 - accuracy: 0.6771\n",
            "Epoch 14: val_loss did not improve from 4.29369\n",
            "105/105 [==============================] - 12s 111ms/step - loss: 1.5126 - accuracy: 0.6771 - val_loss: 4.3860 - val_accuracy: 0.2259\n",
            "Epoch 15/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.3808 - accuracy: 0.7113\n",
            "Epoch 15: val_loss improved from 4.29369 to 4.21929, saving model to weights.hdf5\n",
            "105/105 [==============================] - 12s 112ms/step - loss: 1.3809 - accuracy: 0.7113 - val_loss: 4.2193 - val_accuracy: 0.2441\n",
            "Epoch 16/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.2548 - accuracy: 0.7356\n",
            "Epoch 16: val_loss did not improve from 4.21929\n",
            "105/105 [==============================] - 12s 111ms/step - loss: 1.2546 - accuracy: 0.7358 - val_loss: 4.3059 - val_accuracy: 0.2407\n",
            "Epoch 17/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.1485 - accuracy: 0.7635\n",
            "Epoch 17: val_loss did not improve from 4.21929\n",
            "105/105 [==============================] - 12s 110ms/step - loss: 1.1486 - accuracy: 0.7635 - val_loss: 4.2875 - val_accuracy: 0.2396\n",
            "Epoch 18/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.0574 - accuracy: 0.7867\n",
            "Epoch 18: val_loss did not improve from 4.21929\n",
            "105/105 [==============================] - 12s 110ms/step - loss: 1.0575 - accuracy: 0.7865 - val_loss: 4.2339 - val_accuracy: 0.2475\n",
            "Epoch 19/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9909 - accuracy: 0.8048\n",
            "Epoch 19: val_loss did not improve from 4.21929\n",
            "105/105 [==============================] - 12s 111ms/step - loss: 0.9910 - accuracy: 0.8047 - val_loss: 4.2785 - val_accuracy: 0.2571\n",
            "Epoch 20/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9282 - accuracy: 0.8245\n",
            "Epoch 20: val_loss did not improve from 4.21929\n",
            "105/105 [==============================] - 12s 113ms/step - loss: 0.9281 - accuracy: 0.8245 - val_loss: 4.3090 - val_accuracy: 0.2578\n",
            "Epoch 21/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8609 - accuracy: 0.8376\n",
            "Epoch 21: val_loss did not improve from 4.21929\n",
            "105/105 [==============================] - 11s 109ms/step - loss: 0.8610 - accuracy: 0.8375 - val_loss: 4.3196 - val_accuracy: 0.2558\n",
            "Epoch 22/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8447 - accuracy: 0.8434\n",
            "Epoch 22: val_loss did not improve from 4.21929\n",
            "105/105 [==============================] - 12s 110ms/step - loss: 0.8447 - accuracy: 0.8435 - val_loss: 4.3722 - val_accuracy: 0.2524\n",
            "Epoch 23/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7963 - accuracy: 0.8585\n",
            "Epoch 23: val_loss did not improve from 4.21929\n",
            "105/105 [==============================] - 12s 114ms/step - loss: 0.7962 - accuracy: 0.8585 - val_loss: 4.3833 - val_accuracy: 0.2556\n",
            "Epoch 24/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7557 - accuracy: 0.8667\n",
            "Epoch 24: val_loss did not improve from 4.21929\n",
            "105/105 [==============================] - 12s 113ms/step - loss: 0.7556 - accuracy: 0.8669 - val_loss: 4.4728 - val_accuracy: 0.2463\n",
            "Epoch 25/1000\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7279 - accuracy: 0.8760\n",
            "Epoch 25: val_loss did not improve from 4.21929\n",
            "105/105 [==============================] - 12s 112ms/step - loss: 0.7285 - accuracy: 0.8758 - val_loss: 4.3693 - val_accuracy: 0.2580\n",
            "Epoch 26/1000\n",
            "  8/105 [=>............................] - ETA: 10s - loss: 0.7746 - accuracy: 0.8633"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-29bdd79259e0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train[:], y_train[:],\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     callbacks=[checkpointer, early_stopping])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1787\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m   \"\"\"\n\u001b[0;32m--> 629\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    630\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1166\u001b[0m   \"\"\"\n\u001b[1;32m   1167\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1207\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1206\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1207\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \"\"\"\n\u001b[1;32m    395\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r-POHXU-QYRp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}