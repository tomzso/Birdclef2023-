{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GoUldEz6LT6U"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, ActivityRegularization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZJwKUqEcKJb1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Download the train, validation and test dataset from google colab which were created with the dataset preprocess files\n",
    "\n",
    "dataset = [\n",
    "    '1-IpL9lR5gEFMKGLfDaIIPlrzf2zfnGaN', #https://drive.google.com/file/d/1-IpL9lR5gEFMKGLfDaIIPlrzf2zfnGaN/view?usp=sharing\n",
    "    '1-IilI3zbFwBWIRmi4VvKkI6GkHJ6hXwQ', #https://drive.google.com/file/d/1-IilI3zbFwBWIRmi4VvKkI6GkHJ6hXwQ/view?usp=sharing\n",
    "    '1kKCM-H7cgHTw5p0wQsyNH2Ali-30Bbz-', #https://drive.google.com/file/d/1kKCM-H7cgHTw5p0wQsyNH2Ali-30Bbz-/view?usp=sharing\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# Download the dataset audio files\n",
    "for i, id in enumerate(dataset):\n",
    "  destination = f'{i}.wav'\n",
    "\n",
    "  # Check if the file already exists\n",
    "  if not os.path.exists(destination):\n",
    " \n",
    "    !wget --content-disposition 'https://drive.google.com/uc?export=download&id={id}&confirm=t'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "PJ5wTbo2OWY1",
    "outputId": "944afcd4-ec91-40bf-ef5b-4fa5c1990656"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OU-PlhNPOjFG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to parse TFRecord entries, declaring the metadatas of the TFRecord files\n",
    "def _parse_function(proto):\n",
    "    keys_to_features = {\n",
    "        'data': tf.io.FixedLenFeature([128 * 313 * 3], tf.float32),\n",
    "        'labels': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    parsed_features['data'] = tf.reshape(parsed_features['data'], (128, 313, 3))\n",
    "    return parsed_features['data'], parsed_features['labels']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2Rbs9i3IPhjM"
   },
   "outputs": [],
   "source": [
    "# Load and parse TFRecord datasets for testing, validation,and training\n",
    "# These dataset are pipelined so they are not loaded to the memory.\n",
    "\n",
    "test_dataset = tf.data.TFRecordDataset('test_dataset.tfrecord').map(_parse_function)\n",
    "val_dataset = tf.data.TFRecordDataset('val_dataset.tfrecord').map(_parse_function)\n",
    "train_dataset = tf.data.TFRecordDataset('train_dataset.tfrecord').map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7uKtkSaPrHn",
    "outputId": "1ae36241-b78e-4dd5-f5cc-a57c53b1611c"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "pretrained_model= tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    input_shape=(128,313,3),\n",
    "    pooling='avg',classes=264,\n",
    "    weights='imagenet')\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "\n",
    "\n",
    "model.add(pretrained_model)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(600, activation='relu',kernel_regularizer=keras.regularizers.l2(0.00001)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(600, activation='relu',kernel_regularizer=keras.regularizers.l2(0.00001)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(264, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cicjbe4CPs9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 313, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 313, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 313, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 156, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 156, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 156, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 78, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 78, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 78, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 78, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 39, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 39, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 39, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 39, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 19, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 19, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 19, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 19, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "pretrained_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KhtRiTgXPu_x"
   },
   "outputs": [],
   "source": [
    "# Prefetch datasets for better performance\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Shuffle training dataset\n",
    "train_dataset = train_dataset.shuffle(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define early stopping and checkpoint callbacks\n",
    "patience = 5\n",
    "early_stopping=EarlyStopping(patience=patience, verbose=2)\n",
    "checkpointer=ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDdjRkzoP0jZ",
    "outputId": "aea2e7c8-a3f4-46d9-f0b3-9f2933ffca28",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "202/202 [==============================] - 177s 774ms/step - loss: 5.0852 - accuracy: 0.0614 - val_loss: 5.3161 - val_accuracy: 0.0398\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.31608, saving model to weights.hdf5\n",
      "Epoch 2/30\n",
      "202/202 [==============================] - 144s 712ms/step - loss: 4.5445 - accuracy: 0.1200 - val_loss: 4.9696 - val_accuracy: 0.0843\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.31608 to 4.96957, saving model to weights.hdf5\n",
      "Epoch 3/30\n",
      "202/202 [==============================] - 149s 739ms/step - loss: 4.2491 - accuracy: 0.1586 - val_loss: 4.7346 - val_accuracy: 0.1057\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.96957 to 4.73460, saving model to weights.hdf5\n",
      "Epoch 4/30\n",
      "202/202 [==============================] - 141s 698ms/step - loss: 4.0361 - accuracy: 0.1878 - val_loss: 4.6889 - val_accuracy: 0.1201\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.73460 to 4.68889, saving model to weights.hdf5\n",
      "Epoch 5/30\n",
      "202/202 [==============================] - 139s 686ms/step - loss: 3.8575 - accuracy: 0.2132 - val_loss: 4.6762 - val_accuracy: 0.1268\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.68889 to 4.67617, saving model to weights.hdf5\n",
      "Epoch 6/30\n",
      "202/202 [==============================] - 138s 684ms/step - loss: 3.7096 - accuracy: 0.2322 - val_loss: 4.6648 - val_accuracy: 0.1390\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.67617 to 4.66477, saving model to weights.hdf5\n",
      "Epoch 7/30\n",
      "202/202 [==============================] - 138s 682ms/step - loss: 3.5864 - accuracy: 0.2509 - val_loss: 4.6806 - val_accuracy: 0.1425\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.66477\n",
      "Epoch 8/30\n",
      "202/202 [==============================] - 138s 682ms/step - loss: 3.4776 - accuracy: 0.2682 - val_loss: 4.7173 - val_accuracy: 0.1485\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.66477\n",
      "Epoch 9/30\n",
      "202/202 [==============================] - 138s 682ms/step - loss: 3.3879 - accuracy: 0.2808 - val_loss: 4.7416 - val_accuracy: 0.1504\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.66477\n",
      "Epoch 10/30\n",
      "202/202 [==============================] - 137s 679ms/step - loss: 3.2940 - accuracy: 0.2935 - val_loss: 4.7174 - val_accuracy: 0.1577\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.66477\n",
      "Epoch 11/30\n",
      "202/202 [==============================] - 142s 701ms/step - loss: 3.2125 - accuracy: 0.3070 - val_loss: 4.7633 - val_accuracy: 0.1598\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.66477\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset.batch(batch_size),\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_dataset.batch(batch_size),\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download weights if needed\n",
    "\n",
    "!wget --content-disposition 'https://drive.google.com/uc?export=download&id=16nsgJFzI7bIwovAvIVJNNNOpXL6B3abM&confirm=t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 28s 608ms/step - loss: 93.9080 - accuracy: 0.0037\n"
     ]
    }
   ],
   "source": [
    "# Prefetch datasets for better performance\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Shuffle training dataset\n",
    "train_dataset = train_dataset.shuffle(5)\n",
    "\n",
    "\n",
    "model.load_weights('weights.hdf5')\n",
    "batch_size = 128\n",
    "\n",
    "evaluation_result = model.evaluate(test_dataset.batch(batch_size))\n",
    "\n",
    "loss_value = evaluation_result[0]\n",
    "accuracy_value = evaluation_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'the test accuracy is {accuracy_value}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
